# ğŸ“˜ **Customer Credit Risk â€“ Data Preprocessing & Feature Engineering Project**

---

## ğŸ¦ **Project Overview**
This project demonstrates **complete data preprocessing** and **feature engineering** for a fintech credit-risk dataset to prepare it for Machine Learning modeling.

---

# ğŸ–¼ï¸ **ğŸ“Œ Screenshot 1: Dataset Preview**
â¡ï¸ ![Screenshot](Image/ss.png)

---

Data is collected from:
- ğŸ“„ **CSV file** (main credit dataset)  
- ğŸ—‚ï¸ **JSON metadata file**  
- ğŸ““ **Jupyter Notebook pipeline**  
- ğŸ§¹ **Cleaned final dataset**  
- ğŸ“‘ **Preprocessing Report (DOCX)**  

---

# ğŸ“ **Dataset Sources**
- **credit_dataset.csv** â€“ Raw credit dataset  
- **cleaned_transformed_credit_dataset.csv** â€“ Fully processed ML-ready dataset  
- **customer_metadata.json** â€“ Additional customer info  
- **customers.ipynb** â€“ Notebook containing the full pipeline  
- **Preprocessing_Report.docx** â€“ Final documentation report  

---

# ğŸ§¹ **1. Missing Value Treatment**
âœ” Median imputation for numerical features (age, annual_income, loan_amount, credit_score)  
âœ” Most-frequent imputation for categorical features (gender, employment_type)  
âœ” Missing indicator flags added for annual_income & credit_score  
âœ” Random Sample Imputation used for income distribution preservation  
âœ” KNN Imputer & MICE applied for multivariate numeric imputations  

âœ¨ **Effectiveness:**  
All missing values were handled safely while maintaining realistic distributions.

---

# ğŸš¨ **2. Outlier Handling**
âœ” Winsorization (1%â€“99%) for income, loan amount, credit score  
âœ” IQR-based outlier flags created  
âœ” Extreme values capped, not removed  

âœ¨ **Effectiveness:**  
Outlier impact reduced without distorting dataset structure.

---

# ğŸ”¤ **3. Encoding Techniques**
âœ” **Ordinal Encoding** â†’ education_level  
âœ” **Label Encoding** â†’ gender  
âœ” **One-Hot Encoding** â†’ region, loan_purpose  
âœ” **Binning** â†’ repayment history, income quartiles  
âœ” **KMeans Clustering** â†’ transaction_count groups  

âœ¨ **Effectiveness:**  
All categorical & numerical attributes converted into ML-compatible formats.

---

# ğŸ“ **4. Scaling & Transformations**
âœ” **StandardScaler** â†’ annual_income, loan_amount  
âœ” **MinMaxScaler** â†’ normalized income/spending  
âœ” **RobustScaler** â†’ spending_ratio  
âœ” **Log, Sqrt, Reciprocal Transformations** â†’ reduce skew  
âœ” **Box-Cox & Yeo-Johnson** â†’ normalize numerical distributions  

âœ¨ **Why?**  
Creates smoother distributions â†’ better ML model performance & stability.

---

# ğŸ› ï¸ **5. Feature Engineering**
New predictive features created:

- ğŸ’° **Debt-to-Income Ratio**  
- ğŸ“Š **Average Monthly Transactions**  
- ğŸ§® **Spending-to-Income Ratio**  
- ğŸ“… **Tenure (days, months, years)**  
- ğŸ” **Credit Score >700 Flag**  
- ğŸ“ˆ **Loan-to-Income Percentage**  

âœ¨ **Usefulness:**  
These derived features significantly boost model prediction power.

---

# ğŸ“Š **6. Final Dataset Readiness**
After processing:

- âœ” Missing values: **0**  
- âœ” All categorical variables encoded  
- âœ” Scaled numerical features  
- âœ” Outliers handled  
- âœ” New features constructed  
- âœ” Fully ML-ready dataset  

ğŸ“‚ **Final Shape:** *(Add shape here after checking dataframe)*  

Perfect for:
- Logistic Regression  
- Random Forest  
- XGBoost  
- SVM  
- ANN models  

---

# ğŸ **Conclusion**
This project successfully demonstrates:
- Full preprocessing  
- Outlier handling  
- Encoding  
- Scaling  
- Transformation  
- Feature engineering  
- ML-ready dataset creation  

You now have a complete pipeline for credit-risk modeling in production-grade systems. ğŸš€

---